{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fcfc712",
   "metadata": {},
   "source": [
    "# Validation of PyPSA-Eur model inputs focusing on the generation and flows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f912d2c",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149667af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pypsa\n",
    "import pycountry\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "year = 2023\n",
    "network_path = \"../results/validation_2023/networks/new_base_s_39__3H_2025.nc\"\n",
    "ember_monthly_data_path = \"../ember_data/europe_monthly_full_release_long_format.csv\"\n",
    "ember_yearly_data_path = \"../ember_data/yearly_full_release_long_format.csv\"\n",
    "power_flows_data_path = \"../entsoe_data/physical_energy_power_flows_2023.csv\"\n",
    "\n",
    "countries = ['AL', 'AT', 'BA', 'BE', 'BG', 'CH', 'CY', 'CZ', 'DE', 'DK', 'EE', 'ES',\n",
    "             'FI', 'FR', 'GB', 'GR', 'HR', 'HU', 'IE', 'IT', 'LT', 'LU', 'LV', 'ME',\n",
    "             'MK', 'MT', 'NL', 'NO', 'PL', 'PT', 'RO', 'RS', 'SE', 'SI', 'SK']\n",
    "\n",
    "color_dict = {\n",
    "    \"Bioenergy\": \"#baa741\",\n",
    "    \"Gas\": \"#e05b09\",\n",
    "    \"Hard coal\": \"#545454\",\n",
    "    \"Hydro\": \"#298c81\",\n",
    "    \"Lignite\": \"#826837\",\n",
    "    \"Nuclear\": \"#ff8c00\",\n",
    "    \"Offshore wind\": \"#6895dd\",\n",
    "    \"Onshore wind\": \"#235ebc\",\n",
    "    \"Other fossil\": \"#000000\",\n",
    "    \"Other renewables\": \"#e3d37d\",\n",
    "    \"Solar\": \"#f9d002\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5069a8",
   "metadata": {},
   "source": [
    "## Load data from ember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c53dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pypsa.Network(network_path)\n",
    "ember_monthly = pd.read_csv(ember_monthly_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248eb7a",
   "metadata": {},
   "source": [
    "## Helper function to detect columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_column(columns, keywords):\n",
    "    for keyword in keywords:\n",
    "        for col in columns:\n",
    "            if keyword.lower() in col.lower():\n",
    "                return col\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ecde58",
   "metadata": {},
   "source": [
    "## Process Ember generation data (Yearly CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a9fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ember_generation_yearly():\n",
    "    print(f\"Processing yearly CSV: {ember_yearly_data_path}\")\n",
    "    if not os.path.exists(ember_yearly_data_path):\n",
    "        print(f\"Yearly CSV not found at {ember_yearly_data_path}. Falling back to monthly aggregation.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(ember_yearly_data_path)\n",
    "        print(f\"Yearly CSV loaded. Shape: {df.shape}\")\n",
    "        print(f\"Columns: {df.columns.tolist()}\")\n",
    "        \n",
    "        iso_col = detect_column(df.columns, ['iso 3 code', 'iso3', 'country code'])\n",
    "        variable_col = detect_column(df.columns, ['variable', 'fuel', 'technology'])\n",
    "        value_col = detect_column(df.columns, ['value', 'generation', 'amount'])\n",
    "        unit_col = detect_column(df.columns, ['unit'])\n",
    "        subcategory_col = detect_column(df.columns, ['subcategory', 'category'])\n",
    "        continent_col = detect_column(df.columns, ['continent', 'region'])\n",
    "        year_col = detect_column(df.columns, ['year', 'date'])\n",
    "\n",
    "        print(f\"Detected columns: ISO={iso_col}, Variable={variable_col}, Value={value_col}, \"\n",
    "              f\"Unit={unit_col}, Subcategory={subcategory_col}, Continent={continent_col}, Year={year_col}\")\n",
    "\n",
    "        def iso3_to_iso2(iso3):\n",
    "            try:\n",
    "                return pycountry.countries.get(alpha_3=iso3).alpha_2\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        if iso_col:\n",
    "            df[\"ISO\"] = df[iso_col].apply(iso3_to_iso2)\n",
    "        else:\n",
    "            print(\"Warning: ISO column not found. Assuming 'ISO' column exists.\")\n",
    "            iso_col = \"ISO\"\n",
    "\n",
    "        filters = []\n",
    "        if continent_col:\n",
    "            filters.append(df[continent_col] == \"Europe\")\n",
    "        if iso_col:\n",
    "            filters.append(df[\"ISO\"].isin(countries))\n",
    "        if unit_col:\n",
    "            filters.append(df[unit_col] == \"TWh\")\n",
    "        if subcategory_col:\n",
    "            filters.append(df[subcategory_col] == \"Fuel\")\n",
    "        if year_col:\n",
    "            filters.append(df[year_col].astype(str).str.startswith(str(year)))\n",
    "\n",
    "        if filters:\n",
    "            df = df[np.logical_and.reduce(filters)]\n",
    "        print(f\"After filtering: Shape {df.shape}\")\n",
    "\n",
    "        required_cols = [\"ISO\", variable_col or \"Variable\", value_col or \"Value\"]\n",
    "        available_cols = [col for col in required_cols if col in df.columns]\n",
    "        df = df[available_cols]\n",
    "        df = df.rename(columns={variable_col: \"Variable\", value_col: \"Value\"})\n",
    "\n",
    "        df = df.groupby([\"ISO\", \"Variable\"], as_index=False)[\"Value\"].sum()\n",
    "        print(f\"Processed yearly data sample:\\n{df.head().to_string()}\")\n",
    "        return df.set_index([\"ISO\", \"Variable\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing yearly CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "ember_generation_yearly = process_ember_generation_yearly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dee079b",
   "metadata": {},
   "source": [
    "## Process Ember generation data (Monthly CSV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58461253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ember_generation_monthly():\n",
    "    print(f\"Processing monthly CSV: {ember_monthly_data_path}\")\n",
    "    df = ember_monthly[ember_monthly[\"Continent\"] == \"Europe\"].copy()\n",
    "    print(f\"Monthly CSV loaded. Shape: {df.shape}\")\n",
    "\n",
    "    def iso3_to_iso2(iso3):\n",
    "        try:\n",
    "            return pycountry.countries.get(alpha_3=iso3).alpha_2\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df[\"ISO\"] = df[\"ISO 3 code\"].apply(iso3_to_iso2)\n",
    "    df = df[df[\"ISO\"].isin(countries)]\n",
    "    df = df[df[\"Date\"].str.startswith(str(year))]\n",
    "    df = df[df[\"Unit\"] == \"TWh\"]\n",
    "    df = df[df[\"Subcategory\"] == \"Fuel\"]\n",
    "    df = df[[\"ISO\", \"Date\", \"Variable\", \"Value\", \"Unit\"]]\n",
    "\n",
    "    df_yearly = df.groupby([\"ISO\", \"Variable\"], as_index=False)[\"Value\"].sum()\n",
    "    df_yearly[\"Unit\"] = \"TWh\"\n",
    "    print(f\"Processed monthly aggregated data sample:\\n{df_yearly.head().to_string()}\")\n",
    "    return df_yearly.set_index([\"ISO\", \"Variable\"]).drop([\"Unit\"], axis=1)\n",
    "\n",
    "ember_generation_monthly = process_ember_generation_monthly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f62da",
   "metadata": {},
   "source": [
    "## Wrapper function to choose processing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ember_generation(use_yearly=False):\n",
    "    if use_yearly:\n",
    "        result = process_ember_generation_yearly()\n",
    "        if result is not None:\n",
    "            return result\n",
    "        print(\"Falling back to monthly aggregation due to yearly CSV issues.\")\n",
    "    return process_ember_generation_monthly()\n",
    "\n",
    "ember_generation = process_ember_generation(use_yearly=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5c4b97",
   "metadata": {},
   "source": [
    "## Process PyPSA-Eur model generation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a72d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pypsa_generation():\n",
    "    pypsa_to_ember = {\n",
    "        \"biomass\": \"Bioenergy\", \"Bioenergy\": \"Bioenergy\",\n",
    "        \"gas\": \"Gas\", \"Gas\": \"Gas\", \"CCGT\": \"Gas\", \"OCGT\": \"Gas\",\n",
    "        \"coal\": \"Hard coal\", \"Hard coal\": \"Hard coal\",\n",
    "        \"lignite\": \"Lignite\", \"Lignite\": \"Lignite\",\n",
    "        \"hydro\": \"Hydro\", \"Hydro\": \"Hydro\", \"PHS\": \"Hydro\", \"ror\": \"Hydro\",\n",
    "        \"Nuclear\": \"Nuclear\", \"nuclear\": \"Nuclear\",\n",
    "        \"offwind-ac\": \"Offshore wind\", \"offwind-dc\": \"Offshore wind\",\n",
    "        \"offwind-float\": \"Offshore wind\", \"Offshore wind\": \"Offshore wind\",\n",
    "        \"onwind\": \"Onshore wind\", \"Onshore wind\": \"Onshore wind\",\n",
    "        \"oil\": \"Other fossil\", \"Other fossil\": \"Other fossil\",\n",
    "        \"geothermal\": \"Other renewables\", \"Other renewables\": \"Other renewables\",\n",
    "        \"solar\": \"Solar\", \"solar-hsat\": \"Solar\", \"Solar\": \"Solar\"\n",
    "    }\n",
    "\n",
    "    gen_meta = n.generators[[\"bus\", \"carrier\"]].copy()\n",
    "    gen_meta.loc[:, \"country\"] = gen_meta[\"bus\"].str[:2]\n",
    "    gen_energy = n.generators_t.p.T.multiply(n.snapshot_weightings.generators).T.sum(axis=0) / 1e6  # MWh to TWh\n",
    "    gen_energy.index.name = \"generator\"\n",
    "    gen_energy = gen_energy.reset_index().rename(columns={0: \"Value\"})\n",
    "    gen_energy = gen_energy.merge(gen_meta, left_on=\"generator\", right_index=True)\n",
    "    gen_grouped = gen_energy.groupby([\"country\", \"carrier\"], as_index=False)[\"Value\"].sum()\n",
    "    gen_grouped[\"Ember_Variable\"] = gen_grouped[\"carrier\"].map(pypsa_to_ember).fillna(gen_grouped[\"carrier\"])\n",
    "    gen_renamed = gen_grouped.groupby([\"country\", \"Ember_Variable\"], as_index=False)[\"Value\"].sum()\n",
    "    gen_renamed = gen_renamed.rename(columns={\"country\": \"ISO\", \"Ember_Variable\": \"Variable\"})\n",
    "\n",
    "    sto_meta = n.storage_units[[\"bus\", \"carrier\"]].copy()\n",
    "    sto_meta.loc[:, \"country\"] = sto_meta[\"bus\"].str[:2]\n",
    "    sto_energy = n.storage_units_t.p.T.multiply(n.snapshot_weightings.stores).T.sum(axis=0) / 1e6  # MWh to TWh\n",
    "    sto_energy.index.name = \"storage_unit\"\n",
    "    sto_energy = sto_energy.reset_index().rename(columns={0: \"Value\"})\n",
    "    sto_energy = sto_energy.merge(sto_meta, left_on=\"storage_unit\", right_index=True)\n",
    "    sto_grouped = sto_energy.groupby([\"country\", \"carrier\"], as_index=False)[\"Value\"].sum()\n",
    "    sto_grouped[\"Ember_Variable\"] = sto_grouped[\"carrier\"].map(pypsa_to_ember).fillna(sto_grouped[\"carrier\"])\n",
    "    sto_renamed = sto_grouped.groupby([\"country\", \"Ember_Variable\"], as_index=False)[\"Value\"].sum()\n",
    "    sto_renamed = sto_renamed.rename(columns={\"country\": \"ISO\", \"Ember_Variable\": \"Variable\"})\n",
    "\n",
    "    gen_and_sto = pd.concat([gen_renamed, sto_renamed], ignore_index=True)\n",
    "    gen_and_sto = gen_and_sto.groupby([\"ISO\", \"Variable\"], as_index=False)[\"Value\"].sum()\n",
    "    print(f\"PyPSA generation sample:\\n{gen_and_sto.head().to_string()}\")\n",
    "    return gen_and_sto.set_index([\"ISO\", \"Variable\"])\n",
    "\n",
    "pypsa_generation = process_pypsa_generation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8014f0bf",
   "metadata": {},
   "source": [
    "## Process PyPSA generation sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac10c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pypsa_generation_sector():\n",
    "    pypsa_to_ember = {\n",
    "        \"Bioenergy\": \"Bioenergy\", \"urban central solid biomass CHP\": \"Bioenergy\",\n",
    "        \"urban central solid biomass CHP CC\": \"Bioenergy\",\n",
    "        \"gas\": \"Gas\", \"Gas\": \"Gas\", \"CCGT\": \"Gas\", \"OCGT\": \"Gas\", \"urban central gas CHP\": \"Gas\",\n",
    "        \"urban central gas CHP\": \"Gas\", \"urban central gas CHP CC\": \"Gas\",\n",
    "        \"coal\": \"Hard coal\", \"Hard coal\": \"Hard coal\",\"urban central coal CHP\": \"Hard coal\", \n",
    "        \"lignite\": \"Lignite\", \"Lignite\": \"Lignite\", \"urban central lignite CHP\":\"Lignite\", \n",
    "        \"hydro\": \"Hydro\", \"Hydro\": \"Hydro\", \"PHS\": \"Hydro\", \"ror\": \"Hydro\",\n",
    "        \"Nuclear\": \"Nuclear\", \"nuclear\": \"Nuclear\",\n",
    "        \"offwind-ac\": \"Offshore wind\", \"offwind-dc\": \"Offshore wind\",\n",
    "        \"offwind-float\": \"Offshore wind\", \"Offshore wind\": \"Offshore wind\",\n",
    "        \"onwind\": \"Onshore wind\", \"Onshore wind\": \"Onshore wind\",\n",
    "        \"oil\": \"Other fossil\", \"Other fossil\": \"Other fossil\",\n",
    "        \"geothermal\": \"Other renewables\", \"Other renewables\": \"Other renewables\",\n",
    "        \"solar\": \"Solar\", \"solar-hsat\": \"Solar\", \"Solar\": \"Solar\", \"solar rooftop\": \"Solar\"\n",
    "    }\n",
    "\n",
    "    gen_meta = n.generators[[\"bus\", \"carrier\"]].copy()\n",
    "    gen_meta.loc[:, \"country\"] = gen_meta[\"bus\"].str[:2]\n",
    "    # start by aggregating vres\n",
    "    vres_carriers = ['offwind-dc', 'offwind-ac', 'solar', 'solar-hsat', 'offwind-float', 'onwind', 'ror', 'solar rooftop'] # ideally this is not hardcoded !\n",
    "    vres =  n.generators.query(\"carrier in @vres_carriers\").index\n",
    "    gen_energy = n.generators_t.p.T.multiply(n.snapshot_weightings.generators).loc[vres].T.sum(axis=0) / 1e6  # MWh to TWh\n",
    "    gen_energy.index.name = \"generator\"\n",
    "    gen_energy = gen_energy.reset_index().rename(columns={0: \"Value\"})\n",
    "    gen_energy = gen_energy.merge(gen_meta, left_on=\"generator\", right_index=True)\n",
    "    gen_grouped = gen_energy.groupby([\"country\", \"carrier\"], as_index=False)[\"Value\"].sum()\n",
    "    gen_grouped[\"Ember_Variable\"] = gen_grouped[\"carrier\"].map(pypsa_to_ember).fillna(gen_grouped[\"carrier\"])\n",
    "    gen_renamed = gen_grouped.groupby([\"country\", \"Ember_Variable\"], as_index=False)[\"Value\"].sum()\n",
    "    gen_renamed = gen_renamed.rename(columns={\"country\": \"ISO\", \"Ember_Variable\": \"Variable\"})\n",
    "\n",
    "    # then by aggregating thermal generation & biomass\n",
    "    conv_buses = list(\n",
    "        n.generators.query(\"carrier in ['gas', 'coal', 'uranium', 'lignite', 'biomass', 'oil', 'solid biomass', 'unsustainable solid biomass']\").bus\n",
    "    )\n",
    "    AC_buses = n.buses.query(\"carrier == 'AC'\").index\n",
    "    link_meta = n.links[[\"bus1\", \"carrier\"]].copy()\n",
    "    link_meta.loc[:, \"country\"] = link_meta[\"bus1\"].str[:2]\n",
    "\n",
    "    gen_links = n.links.query(\"bus0 in @conv_buses and bus1 in @AC_buses\").index\n",
    "    gen_energy_links = -n.links_t.p1[gen_links].T.multiply(n.snapshot_weightings.generators).T.sum(axis=0) / 1e6\n",
    "    gen_energy_links.index.name = \"links\"\n",
    "\n",
    "    gen_energy_links = gen_energy_links.reset_index().rename(columns={0: \"Value\"})\n",
    "    gen_energy_links = gen_energy_links.merge(link_meta, left_on=\"links\", right_index=True)\n",
    "    gen_grouped_links = gen_energy_links.groupby([\"country\", \"carrier\"], as_index=False)[\"Value\"].sum()\n",
    "    gen_grouped_links[\"Ember_Variable\"] = gen_grouped_links[\"carrier\"].map(pypsa_to_ember).fillna(gen_grouped_links[\"carrier\"])\n",
    "    gen_renamed_links = gen_grouped_links.groupby([\"country\", \"Ember_Variable\"], as_index=False)[\"Value\"].sum()\n",
    "    gen_renamed_links = gen_renamed_links.rename(columns={\"country\": \"ISO\", \"Ember_Variable\": \"Variable\"})\n",
    "\n",
    "    # and finally aggregating storage values\n",
    "    sto_meta = n.storage_units[[\"bus\", \"carrier\"]].copy()\n",
    "    sto_meta.loc[:, \"country\"] = sto_meta[\"bus\"].str[:2]\n",
    "    sto_energy = n.storage_units_t.p.T.multiply(n.snapshot_weightings.stores).T.sum(axis=0) / 1e6  # MWh to TWh\n",
    "    sto_energy.index.name = \"storage_unit\"\n",
    "    sto_energy = sto_energy.reset_index().rename(columns={0: \"Value\"})\n",
    "    sto_energy = sto_energy.merge(sto_meta, left_on=\"storage_unit\", right_index=True)\n",
    "    sto_grouped = sto_energy.groupby([\"country\", \"carrier\"], as_index=False)[\"Value\"].sum()\n",
    "    sto_grouped[\"Ember_Variable\"] = sto_grouped[\"carrier\"].map(pypsa_to_ember).fillna(sto_grouped[\"carrier\"])\n",
    "    sto_renamed = sto_grouped.groupby([\"country\", \"Ember_Variable\"], as_index=False)[\"Value\"].sum()\n",
    "    sto_renamed = sto_renamed.rename(columns={\"country\": \"ISO\", \"Ember_Variable\": \"Variable\"})\n",
    "\n",
    "    gen_and_sto = pd.concat([gen_renamed, gen_renamed_links, sto_renamed], ignore_index=True)\n",
    "    gen_and_sto = gen_and_sto.groupby([\"ISO\", \"Variable\"], as_index=False)[\"Value\"].sum()\n",
    "    print(f\"PyPSA generation sample:\\n{gen_and_sto.head().to_string()}\")\n",
    "    return gen_and_sto.set_index([\"ISO\", \"Variable\"])\n",
    "\n",
    "pypsa_generation_sector = process_pypsa_generation_sector()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61852add",
   "metadata": {},
   "source": [
    "## Compare Ember processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fbe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def compare_ember_processing(df_yearly, df_monthly, country_iso=\"DE\", year=None):\n",
    "    print(f\"Comparing Ember processing for {country_iso}\")\n",
    "   \n",
    "    def get_country_data(df, iso):\n",
    "        if df is None:\n",
    "            return pd.Series()\n",
    "        \n",
    "        # Add debugging prints\n",
    "        print(f\"\\nDebug for df: index type = {type(df.index)}, shape = {df.shape}\")\n",
    "        if isinstance(df.index, pd.MultiIndex):\n",
    "            print(f\"MultiIndex levels: {df.index.names}\")\n",
    "            print(f\"Level 0 unique values: {df.index.get_level_values(0).unique()[:10]}...\")  # First 10 to avoid too much output\n",
    "            print(f\"Level 1 unique values: {df.index.get_level_values(1).unique()[:10]}...\")\n",
    "        else:\n",
    "            print(f\"Single index name: {df.index.name}\")\n",
    "            print(f\"Columns: {df.columns.tolist()}\")\n",
    "        \n",
    "        if isinstance(df.index, pd.MultiIndex):\n",
    "            try:\n",
    "                unstacked = df.unstack(level=1).fillna(0)\n",
    "                print(f\"After unstack, index unique: {unstacked.index.unique()[:10]}...\")\n",
    "                if iso in unstacked.index:\n",
    "                    data = unstacked.loc[iso]\n",
    "                else:\n",
    "                    print(f\"ISO '{iso}' not found in unstacked index.\")\n",
    "                    data = pd.Series()\n",
    "            except Exception as e:\n",
    "                print(f\"Error in unstack/loc: {e}\")\n",
    "                data = pd.Series()\n",
    "            data = data[data > 0]\n",
    "        else:\n",
    "            try:\n",
    "                sliced = df.xs(iso, level=\"ISO\")\n",
    "                print(f\"After xs, shape: {sliced.shape}, columns: {sliced.columns.tolist()}\")\n",
    "                data = sliced[\"Value\"]\n",
    "                data = data[data > 0]\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError in xs or ['Value']: {e}\")\n",
    "                data = pd.Series()\n",
    "            except Exception as e:\n",
    "                print(f\"Other error in else branch: {e}\")\n",
    "                data = pd.Series()\n",
    "        return data\n",
    "    \n",
    "    yearly_data = get_country_data(df_yearly, country_iso)\n",
    "    monthly_data = get_country_data(df_monthly, country_iso)\n",
    "    \n",
    "    if yearly_data.empty and monthly_data.empty:\n",
    "        print(f\"No data found for {country_iso} in either dataframe.\")\n",
    "        return\n",
    "    \n",
    "    techs = list(set(yearly_data.index).union(monthly_data.index))\n",
    "    if not techs:\n",
    "        print(f\"No technologies with positive data for {country_iso}.\")\n",
    "        return\n",
    "        \n",
    "    yearly_values = [yearly_data.get(tech, 0) for tech in techs]\n",
    "    monthly_values = [monthly_data.get(tech, 0) for tech in techs]\n",
    "   \n",
    "    print(f\"Yearly data for {country_iso}:\\n{yearly_data.to_string()}\")\n",
    "    print(f\"Monthly aggregated data for {country_iso}:\\n{monthly_data.to_string()}\")\n",
    "    \n",
    "    plt.style.use('ggplot')\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bar_width = 0.35\n",
    "    x = np.arange(len(techs))\n",
    "    ax.bar(x - bar_width/2, yearly_values, bar_width, label='Yearly CSV', color='skyblue')\n",
    "    ax.bar(x + bar_width/2, monthly_values, bar_width, label='Monthly Aggregated', color='salmon')\n",
    "    ax.set_xlabel('Technology')\n",
    "    ax.set_ylabel('Generation (TWh)')\n",
    "    title_year = f\"{year}\" if year is not None else \"Unknown Year\"\n",
    "    ax.set_title(f'Ember Generation Comparison for {country_iso} (TWh, {title_year})')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(techs, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(True, axis='y')\n",
    "    plt.tight_layout()\n",
    "    \n",
    " \n",
    "    output_year = year if year is not None else \"unknown\"\n",
    "    output_path = f\"results/validation_{output_year}/plots/ember_comparison_de.png\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close() \n",
    "\n",
    "\n",
    "compare_ember_processing(ember_generation_yearly, ember_generation_monthly, country_iso=\"DE\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f167bb",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866eb8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_country_generation_mix_donut_subplots(ember_generation_yearly, country_isos, color_dict=None):\n",
    "    n = len(country_isos)\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(7, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    pivot_df = ember_generation_yearly.unstack(level=1).fillna(0)\n",
    "    pivot_df.columns = pivot_df.columns.get_level_values(1)\n",
    "\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, country_iso in enumerate(country_isos):\n",
    "        ax = axes[idx]\n",
    "        if country_iso not in pivot_df.index:\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f\"{country_iso} not found\")\n",
    "            continue\n",
    "\n",
    "        data = pivot_df.loc[country_iso]\n",
    "        data = data[data > 0]\n",
    "\n",
    "        colors = [color_dict.get(tech, \"#cccccc\") for tech in data.index] if color_dict else plt.cm.Set2.colors[:len(data)]\n",
    "\n",
    "        wedges, texts = ax.pie(\n",
    "            data.values,\n",
    "            labels=None,\n",
    "            startangle=90,\n",
    "            colors=colors,\n",
    "            wedgeprops=dict(width=0.7),\n",
    "            autopct=None\n",
    "        )\n",
    "\n",
    "        for i, wedge in enumerate(wedges):\n",
    "            angle = (wedge.theta2 + wedge.theta1) / 2\n",
    "            x = 0.7 * np.cos(np.deg2rad(angle))\n",
    "            y = 0.7 * np.sin(np.deg2rad(angle))\n",
    "            ax.text(x, y, f\"{int(round(data.values[i]))}\", ha='center', va='center', fontsize=10, color='white', fontweight='bold')\n",
    "\n",
    "        centre_circle = plt.Circle((0, 0), 0.25, color='white', fc='white', linewidth=0)\n",
    "        ax.add_artist(centre_circle)\n",
    "        ax.text(0, 0, country_iso, ha='center', va='center', fontsize=18, fontweight='bold')\n",
    "\n",
    "        if idx == 0:\n",
    "            legend_handles = wedges\n",
    "            legend_labels = data.index\n",
    "\n",
    "    for j in range(len(country_isos), len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    fig.legend(\n",
    "        legend_handles, legend_labels,\n",
    "        loc='upper center',\n",
    "        bbox_to_anchor=(0.5, 1.05),\n",
    "        ncol=4,\n",
    "        fontsize=10,\n",
    "        frameon=True\n",
    "    )\n",
    "\n",
    "    fig.suptitle(f\"Yearly Electricity Generation by Technology\\n(TWh, Ember {year})\", fontsize=16, weight='bold', y=1.12)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    \n",
    "    output_path = f\"results/validation_{year}/plots/donut_subplots.png\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_country_generation_mix_donut_subplots(\n",
    "    ember_generation, \n",
    "    [\"DE\", \"NL\", \"IT\", \"PL\", \"CZ\", \"GR\"], \n",
    "    color_dict=color_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf1c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_country_generation_mix_donut_comparison(df1, df2, country_isos, color_dict=None, df1_label=\"Ember\", df2_label=\"PyPSA\"):\n",
    "    n = len(country_isos)\n",
    "    fig, axes = plt.subplots(n, 2, figsize=(6, 3 * n))\n",
    "    plt.subplots_adjust(wspace=0.05)\n",
    "    if n == 1:\n",
    "        axes = np.array([axes])\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "\n",
    "    def pivot(df):\n",
    "        if isinstance(df.index, pd.MultiIndex):\n",
    "            p = df.unstack(level=1).fillna(0)\n",
    "            p.columns = p.columns.get_level_values(1)\n",
    "        else:\n",
    "            p = df.copy()\n",
    "        return p\n",
    "\n",
    "    pivot1 = pivot(df1)\n",
    "    pivot2 = pivot(df2)\n",
    "\n",
    "    for idx, country_iso in enumerate(country_isos):\n",
    "        for j, (pivot_df, label) in enumerate(zip([pivot1, pivot2], [df1_label, df2_label])):\n",
    "            ax = axes[idx, j]\n",
    "            if country_iso not in pivot_df.index:\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f\"{country_iso} not found\")\n",
    "                continue\n",
    "            data = pivot_df.loc[country_iso]\n",
    "            data = data[data > 0]\n",
    "            colors = [color_dict.get(tech, \"#cccccc\") for tech in data.index] if color_dict else plt.cm.Set2.colors[:len(data)]\n",
    "            wedges, _ = ax.pie(\n",
    "                data.values,\n",
    "                labels=None,\n",
    "                startangle=90,\n",
    "                colors=colors,\n",
    "                wedgeprops=dict(width=0.7),\n",
    "                autopct=None\n",
    "            )\n",
    "            for i, wedge in enumerate(wedges):\n",
    "                angle = (wedge.theta2 + wedge.theta1) / 2\n",
    "                x = 0.7 * np.cos(np.deg2rad(angle))\n",
    "                y = 0.7 * np.sin(np.deg2rad(angle))\n",
    "                ax.text(x, y, f\"{int(round(data.values[i]))}\", ha='center', va='center', fontsize=10, color='white', fontweight='bold')\n",
    "            centre_circle = plt.Circle((0, 0), 0.25, color='white', fc='white', linewidth=0)\n",
    "            ax.add_artist(centre_circle)\n",
    "            total = int(round(data.sum()))\n",
    "            ax.text(0, 0, f\"{total}\", ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "            ax.set_title(f\"{label}\\n{country_iso}\" if idx == 0 else country_iso, fontsize=14, fontweight='bold')\n",
    "            if idx == 0 and j == 0:\n",
    "                legend_handles = wedges\n",
    "                legend_labels = data.index\n",
    "\n",
    "    for i in range(n, axes.shape[0]):\n",
    "        for j in range(2):\n",
    "            axes[i, j].axis('off')\n",
    "\n",
    "    fig.legend(\n",
    "        legend_handles, legend_labels,\n",
    "        loc='upper center',\n",
    "        bbox_to_anchor=(0.5, 1.02),\n",
    "        ncol=4,\n",
    "        fontsize=10,\n",
    "        frameon=True\n",
    "    )\n",
    "    fig.suptitle(\"Yearly Electricity Generation [TWh]\", fontsize=16, weight='bold', y=1.05)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "\n",
    "    output_path = f\"results/validation_{year}/plots/donut_comparison.png\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.show() \n",
    "\n",
    "plot_country_generation_mix_donut_comparison(\n",
    "    ember_generation, \n",
    "    pypsa_generation_sector, \n",
    "    [\"DE\", \"NL\", \"IT\", \"PL\", \"CZ\", \"GR\"], \n",
    "    color_dict=color_dict, \n",
    "    df1_label=\"Ember\", \n",
    "    df2_label=\"PyPSA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b77ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required data\n",
    "# - ember_generation(from process_ember_generation)\n",
    "# - pypsa_generation_sector(from process_pypsa_generation_sector)\n",
    "# Focus countries\n",
    "focus_countries = [\"CZ\", \"DE\", \"GR\", \"IT\", \"NL\", \"PL\"]\n",
    "# same index for comparison\n",
    "common_index = ember_generation.index.intersection(pypsa_generation_sector.index)\n",
    "ember_aligned = ember_generation.loc[common_index].copy()\n",
    "pypsa_aligned = pypsa_generation_sector.loc[common_index].copy()\n",
    "# PyPSA - Ember (positive if PyPSA overestimates)\n",
    "diff_df = pd.DataFrame(index=common_index)\n",
    "diff_df['diff'] = pypsa_aligned['Value'] - ember_aligned['Value']\n",
    "# Calculating continental and country totals\n",
    "total_europe_ember = ember_generation['Value'].sum()\n",
    "country_totals_ember = ember_generation.groupby('ISO')['Value'].sum()\n",
    "# Total generation per technology per country (Ember)\n",
    "tech_country_ember = ember_generation.copy()\n",
    "# Per-technology deviations\n",
    "# (PyPSA - Ember) / Ember_tech_country\n",
    "# if Ember > PyPSA, this will be negative (underestimation)\n",
    "diff_df['rel_dev_tech_pct'] = (diff_df['diff'] / tech_country_ember.loc[common_index, 'Value']) * 100\n",
    "# Calculating absolute percentage error for \"how off\"\n",
    "diff_df['abs_rel_error_pct'] = np.abs(diff_df['diff'] / tech_country_ember.loc[common_index, 'Value']) * 100\n",
    "# (PyPSA - Ember) / total_country_ember\n",
    "# Map country totals to the multiindex\n",
    "diff_df['country_total'] = diff_df.index.get_level_values('ISO').map(country_totals_ember)\n",
    "diff_df['rel_dev_country_pct'] = (diff_df['diff'] / diff_df['country_total']) * 100\n",
    "# 1c. Normalized by Europe total generation (Ember): (PyPSA - Ember) / total_europe_ember\n",
    "diff_df['rel_dev_europe_pct'] = (diff_df['diff'] / total_europe_ember) * 100\n",
    "diff_df = diff_df.drop(columns=['country_total'])\n",
    "diff_df = diff_df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "focus_index = diff_df.index.get_level_values('ISO').isin(focus_countries)\n",
    "diff_df = diff_df.loc[focus_index]\n",
    "# 2. Total generation deviation by country (kept for completeness, but not used in plot/table)\n",
    "country_totals_pypsa = pypsa_generation_sector.groupby('ISO')['Value'].sum()\n",
    "common_countries = country_totals_ember.index.intersection(country_totals_pypsa.index)\n",
    "country_diff = pd.DataFrame(index=common_countries)\n",
    "country_diff['diff_total'] = country_totals_pypsa.loc[common_countries] - country_totals_ember.loc[common_countries]\n",
    "# (PyPSA_total - Ember_total) / Ember_total_country\n",
    "country_diff['rel_dev_country_total_pct'] = (country_diff['diff_total'] / country_totals_ember.loc[common_countries]) * 100\n",
    "# (PyPSA_total - Ember_total) / total_europe_ember\n",
    "country_diff['rel_dev_europe_total_pct'] = (country_diff['diff_total'] / total_europe_ember) * 100\n",
    "country_diff = country_diff.loc[country_diff.index.isin(focus_countries)]\n",
    "output_dir = f\"results/validation_{year}/deviations/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "diff_df.to_csv(os.path.join(output_dir, \"per_tech_deviations_focus.csv\"))\n",
    "country_diff.to_csv(os.path.join(output_dir, \"per_country_total_deviations_focus.csv\"))\n",
    "print(\"Per-technology deviations sample (focus countries):\")\n",
    "print(diff_df.head().to_string())\n",
    "print(\"Per-country total deviations sample (focus countries):\")\n",
    "print(country_diff.head().to_string())\n",
    "def plot_per_country_tech_deviations(df, focus_countries, color_dict, year, output_dir):\n",
    "    plt.style.use('ggplot')\n",
    "    n = len(focus_countries)\n",
    "    rows = (n + 1) // 2 # Two columns\n",
    "    fig, axes = plt.subplots(rows, 2, figsize=(14, 4 * rows), sharey=True)\n",
    "    axes = axes.flatten()\n",
    "  \n",
    "    for i, country in enumerate(focus_countries):\n",
    "        ax = axes[i]\n",
    "        try:\n",
    "            # Fixed: Use xs to slice MultiIndex by ISO level\n",
    "            country_data = df.xs(country, level='ISO')\n",
    "            if country_data.empty:\n",
    "                ax.text(0.5, 0.5, f\"No data for {country}\", ha='center', va='center')\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "           \n",
    "            # NEW: Filter to non-NaN technologies only\n",
    "            valid_mask = country_data['rel_dev_tech_pct'].notna()\n",
    "            if not valid_mask.any():\n",
    "                ax.text(0.5, 0.5, f\"No data for {country}\", ha='center', va='center')\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "           \n",
    "            techs = country_data.index[valid_mask]\n",
    "            y = country_data['rel_dev_tech_pct'][valid_mask]\n",
    "            x = np.arange(len(y))\n",
    "            colors = [color_dict.get(tech, '#cccccc') for tech in techs]\n",
    "            ax.bar(x, y, color=colors, alpha=0.7)\n",
    "            ax.set_title(country)\n",
    "            ax.set_ylabel('Relative Deviation [%]')\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels(techs, rotation=45, ha='right')\n",
    "            ax.grid(True, axis='y')\n",
    "        except KeyError:\n",
    "            ax.text(0.5, 0.5, f\"No data for {country}\", ha='center', va='center')\n",
    "            ax.axis('off')\n",
    "  \n",
    "    for j in range(n, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "  \n",
    "    fig.suptitle(f\"Relative Deviation per Technology per Focus Country ({year})\", y=1.02, fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "  \n",
    "    output_path = os.path.join(output_dir, \"plots/rel_dev_per_tech_per_country_focus.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "plot_per_country_tech_deviations(diff_df, focus_countries, color_dict, year, output_dir)\n",
    "# ---------------------------\n",
    "# Summary Table for Key Carriers\n",
    "# ---------------------------\n",
    "def generate_summary_table(df, key_carriers, focus_countries, year):\n",
    "    full_multi = pd.MultiIndex.from_product([focus_countries, key_carriers], names=['ISO', 'Variable'])\n",
    "    df_full = df.reindex(full_multi).sort_index()\n",
    "    key_index = df_full.index.get_level_values('Variable').isin(key_carriers)\n",
    "    table_df = df_full.loc[key_index, 'rel_dev_tech_pct'].unstack(level='ISO').round(0)\n",
    "    table_df.columns = pd.Index(table_df.columns, name='ISO')\n",
    "    table_df = table_df[focus_countries]\n",
    "    table_str_df = table_df.fillna('-').astype(str) + '%'\n",
    "    def highlight(val):\n",
    "        if val == '-%':\n",
    "            return val\n",
    "        num_str = val[:-1]\n",
    "        try:\n",
    "            num = float(num_str)\n",
    "            if abs(num) > 50:\n",
    "                return f\"**{val}**\"\n",
    "            return val\n",
    "        except ValueError:\n",
    "            return val\n",
    "   \n",
    "    table_highlight = table_str_df.applymap(highlight)\n",
    "   \n",
    "    # n. countries with abs dev >50% / total with data\n",
    "    row_counts = []\n",
    "    for carrier in key_carriers:\n",
    "        row = table_df.loc[carrier]\n",
    "        total_data = row.notna().sum()\n",
    "        high_dev = (abs(row) > 50).sum()\n",
    "        if total_data == 0:\n",
    "            row_counts.append('-')\n",
    "        else:\n",
    "            row_counts.append(f\"{high_dev}/{int(total_data)}\")\n",
    "   \n",
    "  \n",
    "    table_highlight['n. countries with abs dev > 50%'] = row_counts\n",
    "   \n",
    "    # n. carriers with abs dev >50% / total carriers with data\n",
    "    col_counts = []\n",
    "    for country in focus_countries:\n",
    "        col = table_df[country]\n",
    "        total_data = col.notna().sum()\n",
    "        high_dev = (abs(col) > 50).sum()\n",
    "        if total_data == 0:\n",
    "            col_counts.append('-')\n",
    "        else:\n",
    "            col_counts.append(f\"{high_dev}/{int(total_data)}\")\n",
    "   \n",
    " \n",
    "    # Create bottom row with label in index\n",
    "    bottom_data = col_counts + ['']\n",
    "    bottom_df = pd.DataFrame([bottom_data], index=['n. carriers with abs dev > 50%'], columns=table_highlight.columns)\n",
    "   \n",
    "    table_final = pd.concat([table_highlight, bottom_df])\n",
    "   \n",
    "  \n",
    "    print(f\"\\nDeviations from reported ones, {year}, for key carriers and focus countries\")\n",
    "    print(f\"(% difference between TWh in PyPSA-Eur model run and Ember reported TWh) (negative means model run underestimates reported values), absolute deviations > 50% highlighted in red\")\n",
    "    print(table_final.to_markdown())\n",
    "   \n",
    "    return table_final\n",
    "key_carriers = [\"Gas\", \"Hard coal\", \"Lignite\", \"Nuclear\", \"Offshore wind\", \"Onshore wind\", \"Solar\"]\n",
    "# Generate and print the table\n",
    "summary_table = generate_summary_table(diff_df, key_carriers, focus_countries, year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypsa-eur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
